{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Project: Tree-Based Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The \"German Credit\" Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has two classes (these would be considered labels in Machine Learning terms) to describe the worthiness of a personal loan: \"Good\" or \"Bad\". There are predictors related to attributes, such as: checking account status, duration, credit history, purpose of the loan, amount of the loan, savings accounts or bonds, employment duration, installment rate in percentage of disposable income, personal information, other debtors/guarantors, residence duration, property, age, other installment plans, housing, number of existing credits, job information, number of people being liable to provide maintenance for, telephone, and foreign worker status.\n",
    "\n",
    "Many of these predictors are discrete and have been expanded into several 0/1 indicator variables (a.k.a. they have been one-hot-encoded).\n",
    "\n",
    "This dataset has been kindly provided by Professor Dr. Hans Hofmann of the University of Hamburg, and can also be found on the UCI Machine Learning Repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As we have learned in the previous lectures, Decision Trees as a family of algorithms (irrespective to the particular implementation) are powerful algorithms that can produce models with a predictive accuracy higher than that produced by linear models, such as Linear or Logistic Regression. Primarily, this is due to the fact the DT's can model nonlinear relationships, and also have a number of tuning paramters, that allow for the practicioner to achieve the best possible model. An added bonus is the ability to visualize the trained Decision Tree model, which allows for some insight into how the model has produced the predictions that it has. One caveat here, to keep in mind, is that sometimes, due to the size of the dataset (both in the sense of the number of records, as well as the number of features), the visualization might prove to be very large and complex, increasing the difficulty of interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give you a very good example of how Decision Trees can be visualized and interpreted, we would strongly recommend that, before continuing on with solving the problems in this Mini Project, you take the time to read this fanstastic, detailed and informative blog post: http://explained.ai/decision-tree-viz/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Your First Decision Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now it's time to jump straight into the heart of the matter. Your first task, is to build a Decision Tree model, using the aforementioned \"German Credit\" dataset, which contains 1,000 records, and 62 columns (one of them presents the labels, and the other 61 present the potential features for the model.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task, you will be using the scikit-learn library, which comes already pre-installed with the Anaconda Python distribution. In case you're not using that, you can easily install it using pip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before embarking on creating your first model, we would strongly encourage you to read the short tutorial for Decision Trees in scikit-learn (http://scikit-learn.org/stable/modules/tree.html), and then dive a bit deeper into the documentation of the algorithm itself (http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, since you want to be able to present the results of your model, we suggest you take a look at the tutorial for accuracy metrics for classification models (http://scikit-learn.org/stable/modules/model_evaluation.html#classification-report) as well as the more detailed documentation (http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html).\n",
    "\n",
    "Finally, an *amazing* resource that explains the various classification model accuracy metrics, as well as the relationships between them, can be found on Wikipedia: https://en.wikipedia.org/wiki/Confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note: as you've already learned in the Logistic Regression mini project, a standard practice in Machine Learning for achieving the best possible result when training a model is to use hyperparameter tuning, through Grid Search and k-fold Cross Validation. We strongly encourage you to use it here as well, not just because it's standard practice, but also becuase it's not going to be computationally to intensive, due to the size of the dataset that you're working with. Our suggestion here is that you split the data into 70% training, and 30% testing. Then, do the hyperparameter tuning and Cross Validation on the training set, and afterwards to a final test on the testing set.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we pass the torch onto you! You can start building your first Decision Tree model! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "German Credit Dataset details;\n",
    "Description of the German credit dataset.\n",
    "\n",
    "1. Title: German Credit data\n",
    "\n",
    "2. Source Information\n",
    "\n",
    "Professor Dr. Hans Hofmann  \n",
    "Institut f\"ur Statistik und \"Okonometrie  \n",
    "Universit\"at Hamburg  \n",
    "FB Wirtschaftswissenschaften  \n",
    "Von-Melle-Park 5    \n",
    "2000 Hamburg 13 \n",
    "\n",
    "3. Number of Instances:  1000\n",
    "\n",
    "Two datasets are provided.  the original dataset, in the form provided\n",
    "by Prof. Hofmann, contains categorical/symbolic attributes and\n",
    "is in the file \"german.data\".   \n",
    " \n",
    "For algorithms that need numerical attributes, Strathclyde University \n",
    "produced the file \"german.data-numeric\".  This file has been edited \n",
    "and several indicator variables added to make it suitable for \n",
    "algorithms which cannot cope with categorical variables.   Several\n",
    "attributes that are ordered categorical (such as attribute 17) have\n",
    "been coded as integer.    This was the form used by StatLog.\n",
    "\n",
    "\n",
    "6. Number of Attributes german: 20 (7 numerical, 13 categorical)\n",
    "   Number of Attributes german.numer: 24 (24 numerical)\n",
    "\n",
    "\n",
    "7.  Attribute description for german\n",
    "\n",
    "Attribute 1: (qualitative) \n",
    "AccountStatus - AS\n",
    "A11 : ... < 0 DM \n",
    "A12 : 0 <= ... < 200 DM \n",
    "A13 : ... >= 200 DM / salary assignments for at least 1 year \n",
    "A14 : no checking account \n",
    "\n",
    "Attribute 2: (numerical) \n",
    "Duration - D\n",
    "\n",
    "Attribute 3: (qualitative) \n",
    "CreditHistory - CH\n",
    "A30 : no credits taken/ all credits paid back duly \n",
    "A31 : all credits at this bank paid back duly \n",
    "A32 : existing credits paid back duly till now \n",
    "A33 : delay in paying off in the past \n",
    "A34 : critical account/ other credits existing (not at this bank) \n",
    "\n",
    "Attribute 4: (qualitative) \n",
    "Purpose - P\n",
    "A40 : car (new) \n",
    "A41 : car (used) \n",
    "A42 : furniture/equipment \n",
    "A43 : radio/television \n",
    "A44 : domestic appliances \n",
    "A45 : repairs \n",
    "A46 : education \n",
    "A48 : retraining \n",
    "A49 : business \n",
    "A410 : others \n",
    "\n",
    "Attribute 5: (numerical) \n",
    "CreditAmount - CA\n",
    "\n",
    "Attribute 6: (qualitative) \n",
    "Account - Acc\n",
    "A61 : ... < 100 DM \n",
    "A62 : 100 <= ... < 500 DM \n",
    "A63 : 500 <= ... < 1000 DM \n",
    "A64 : .. >= 1000 DM \n",
    "A65 : unknown/ no savings account \n",
    "\n",
    "Attribute 7: (qualitative) \n",
    "EmploymentSince - ES\n",
    "A71 : unemployed \n",
    "A72 : ... < 1 year \n",
    "A73 : 1 <= ... < 4 years \n",
    "A74 : 4 <= ... < 7 years \n",
    "A75 : .. >= 7 years \n",
    "\n",
    "Attribute 8: (numerical) \n",
    "PrecentOfIncome  - POI\n",
    "\n",
    "Attribute 9: (qualitative) \n",
    "PersonalStatus - PS\n",
    "A91 : male - divorced/separated \n",
    "A92 : female - divorced/separated/married \n",
    "A93 : male - single \n",
    "A94 : male - married/widowed \n",
    "A95 : female - single \n",
    "\n",
    "Attribute 10: (qualitative) \n",
    "OtherDebtors - OD\n",
    "A101 : none \n",
    "A102 : co-applicant \n",
    "A103 : guarantor \n",
    "\n",
    "Attribute 11: (numerical) \n",
    "ResidenceSince - RS\n",
    "\n",
    "Attribute 12: (qualitative) \n",
    "Property - Prop\n",
    "A121 : real estate \n",
    "A122 : building society savings agreement/ life insurance \n",
    "A123 : car or other, not in attribute Account \n",
    "A124 : unknown / no property \n",
    "\n",
    "Attribute 13: (numerical) \n",
    "Age - Age\n",
    "\n",
    "Attribute 14: (qualitative) \n",
    "OtherInstallPlans - OIP\n",
    "A141 : bank \n",
    "A142 : stores \n",
    "A143 : none \n",
    "\n",
    "Attribute 15: (qualitative) \n",
    "Housing - H\n",
    "A151 : rent \n",
    "A152 : own \n",
    "A153 : for free \n",
    "\n",
    "Attribute 16: (numerical) \n",
    "NumExistingCredits - NEC\n",
    "\n",
    "Attribute 17: (qualitative) \n",
    "Job - Job\n",
    "A171 : unemployed/ unskilled - non-resident\n",
    "A172 : unskilled - resident\n",
    "A173 : skilled employee / official\n",
    "A174 : management/ self-employed/highly qualified employee/ officer\n",
    "\n",
    "Attribute 18: (numerical) \n",
    "NumMaintenance - NM\n",
    "\n",
    "Attribute 19: (qualitative) \n",
    "Telephone - T\n",
    "A191 : none \n",
    "A192 : yes, registered under the customers name \n",
    "\n",
    "Attribute 20: (qualitative) \n",
    "ForeignWorker - FW\n",
    "A201 : yes \n",
    "A202 : no \n",
    "\n",
    "Attribute 21: (quantitative)\n",
    "GoodCredit - GC\n",
    "1: 1\n",
    "2: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/amardeepsingh/Desktop/MyApps/Education/Springboard/springboardWorkspace/springboard-miniprojects/mini-project-unit_8_2\n",
      "Mini_Project_Tree-Based_Algorithms.ipynb\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here! :)\n",
    "# We load the dataset from the url and convert it into pandas dataframe\n",
    "# german_credit_file_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data'\n",
    "german_credit_file_url = '/Users/amardeepsingh/Desktop/MyApps/Education/Springboard/DataSets/GermanCredit/german.data'\n",
    "german_credit_df = pd.read_csv(german_credit_file_url, sep=\" \", header=None)\n",
    "\n",
    "# The column names are not defined in the original dataset. Therefore, we will add appropriate column names\n",
    "column_names = ['AS','D','CH','P','CA','Acc','ES','POI','PS','OD','RS','Prop','Age','OIP','H','NEC','Job','NM','T','FW','GC']\n",
    "german_credit_df.columns = column_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AS</th>\n",
       "      <th>D</th>\n",
       "      <th>CH</th>\n",
       "      <th>P</th>\n",
       "      <th>CA</th>\n",
       "      <th>Acc</th>\n",
       "      <th>ES</th>\n",
       "      <th>POI</th>\n",
       "      <th>PS</th>\n",
       "      <th>OD</th>\n",
       "      <th>...</th>\n",
       "      <th>Prop</th>\n",
       "      <th>Age</th>\n",
       "      <th>OIP</th>\n",
       "      <th>H</th>\n",
       "      <th>NEC</th>\n",
       "      <th>Job</th>\n",
       "      <th>NM</th>\n",
       "      <th>T</th>\n",
       "      <th>FW</th>\n",
       "      <th>GC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A11</td>\n",
       "      <td>6</td>\n",
       "      <td>A34</td>\n",
       "      <td>A43</td>\n",
       "      <td>1169</td>\n",
       "      <td>A65</td>\n",
       "      <td>A75</td>\n",
       "      <td>4</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>67</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A192</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A12</td>\n",
       "      <td>48</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>5951</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>2</td>\n",
       "      <td>A92</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>22</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14</td>\n",
       "      <td>12</td>\n",
       "      <td>A34</td>\n",
       "      <td>A46</td>\n",
       "      <td>2096</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>49</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A172</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A11</td>\n",
       "      <td>42</td>\n",
       "      <td>A32</td>\n",
       "      <td>A42</td>\n",
       "      <td>7882</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>A103</td>\n",
       "      <td>...</td>\n",
       "      <td>A122</td>\n",
       "      <td>45</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A11</td>\n",
       "      <td>24</td>\n",
       "      <td>A33</td>\n",
       "      <td>A40</td>\n",
       "      <td>4870</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>3</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A124</td>\n",
       "      <td>53</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AS   D   CH    P    CA  Acc   ES  POI   PS    OD  ...  Prop Age   OIP  \\\n",
       "0  A11   6  A34  A43  1169  A65  A75    4  A93  A101  ...  A121  67  A143   \n",
       "1  A12  48  A32  A43  5951  A61  A73    2  A92  A101  ...  A121  22  A143   \n",
       "2  A14  12  A34  A46  2096  A61  A74    2  A93  A101  ...  A121  49  A143   \n",
       "3  A11  42  A32  A42  7882  A61  A74    2  A93  A103  ...  A122  45  A143   \n",
       "4  A11  24  A33  A40  4870  A61  A73    3  A93  A101  ...  A124  53  A143   \n",
       "\n",
       "      H NEC   Job NM     T    FW GC  \n",
       "0  A152   2  A173  1  A192  A201  1  \n",
       "1  A152   1  A173  1  A191  A201  2  \n",
       "2  A152   1  A172  2  A191  A201  1  \n",
       "3  A153   1  A173  2  A191  A201  1  \n",
       "4  A153   2  A173  2  A191  A201  2  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "german_credit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([67, 22, 49, 45, 53, 35, 61, 28, 25, 24, 60, 32, 44, 31, 48, 26, 36,\n",
       "       39, 42, 34, 63, 27, 30, 57, 33, 37, 58, 23, 29, 52, 50, 46, 51, 41,\n",
       "       40, 66, 47, 56, 54, 20, 21, 38, 70, 65, 74, 68, 43, 55, 64, 75, 19,\n",
       "       62, 59])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "german_credit_df.Age.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AS', 'CH', 'P', 'Acc', 'ES', 'PS', 'OD', 'Prop', 'OIP', 'H', 'Job', 'T', 'FW']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AS</th>\n",
       "      <th>D</th>\n",
       "      <th>CH</th>\n",
       "      <th>P</th>\n",
       "      <th>CA</th>\n",
       "      <th>Acc</th>\n",
       "      <th>ES</th>\n",
       "      <th>POI</th>\n",
       "      <th>PS</th>\n",
       "      <th>OD</th>\n",
       "      <th>...</th>\n",
       "      <th>Prop</th>\n",
       "      <th>Age</th>\n",
       "      <th>OIP</th>\n",
       "      <th>H</th>\n",
       "      <th>NEC</th>\n",
       "      <th>Job</th>\n",
       "      <th>NM</th>\n",
       "      <th>T</th>\n",
       "      <th>FW</th>\n",
       "      <th>GC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1169</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5951</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2096</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7882</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4870</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AS   D  CH  P    CA  Acc  ES  POI  PS  OD  ...  Prop  Age  OIP  H  NEC  \\\n",
       "0   0   6   4  4  1169    4   4    4   2   0  ...     0   67    2  1    2   \n",
       "1   1  48   2  4  5951    0   2    2   1   0  ...     0   22    2  1    1   \n",
       "2   3  12   4  7  2096    0   3    2   2   0  ...     0   49    2  1    1   \n",
       "3   0  42   2  3  7882    0   3    2   2   2  ...     1   45    2  2    1   \n",
       "4   0  24   3  0  4870    0   2    3   2   0  ...     3   53    2  2    2   \n",
       "\n",
       "   Job  NM  T  FW  GC  \n",
       "0    2   1  1   0   1  \n",
       "1    2   1  0   0   2  \n",
       "2    1   2  0   0   1  \n",
       "3    2   2  0   0   1  \n",
       "4    2   2  0   0   2  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since a lot of data is in the String format which we can not feed to classifier, \n",
    "# we will encode the column values to labeled integer values\n",
    "# We only encode the non-integer type of columns\n",
    "columns_to_encode = german_credit_df.select_dtypes(include=[object]).columns.tolist()\n",
    "print(columns_to_encode)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "for column_name in columns_to_encode:\n",
    "    german_credit_df[column_name] = le.fit_transform(german_credit_df[column_name])\n",
    "german_credit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 20) (700,)\n",
      "(300, 20) (300,)\n"
     ]
    }
   ],
   "source": [
    "# Extract the predictor values (Good Credit) from the dataframe\n",
    "y = german_credit_df.GC\n",
    "X_train, X_test, y_train, y_test = train_test_split(german_credit_df[column_names[:20]], y, test_size=0.3)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_model = DecisionTreeClassifier()\n",
    "dtc_model.fit(X_train,y_train)\n",
    "y_pred = dtc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6566666666666666"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_test.Age, y_test, label='Actual', marker='o', s=20, c='r')\n",
    "plt.scatter(X_test.Age, y_pred, label='Predicted', marker='x', s=10, c='g')\n",
    "plt.legend(prop={'size':10})\n",
    "plt.xlabel(\"Age in years\")\n",
    "plt.ylabel(\"Good Credit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After you've built the best model you can, now it's time to visualize it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rememeber that amazing blog post from a few paragraphs ago, that demonstrated how to visualize and interpret the results of your Decision Tree model. We've seen that this can perform very well, but let's see how it does on the \"German Credit\" dataset that we're working on, due to it being a bit larger than the one used by the blog authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we're going to need to install their package. If you're using Anaconda, this can be done easily by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphviz==0.8.1\n",
      "  Downloading https://files.pythonhosted.org/packages/82/cc/668725769a1b184322019b494bbdfbb82bbef5cecc1dd8be6f778cf1422b/graphviz-0.8.1-py2.py3-none-any.whl\n",
      "\u001b[31mdtreeviz 0.8.1 has requirement graphviz>=0.9, but you'll have graphviz 0.8.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: graphviz\n",
      "  Found existing installation: graphviz 0.13.2\n",
      "    Uninstalling graphviz-0.13.2:\n",
      "      Successfully uninstalled graphviz-0.13.2\n",
      "Successfully installed graphviz-0.8.1\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install graphviz==0.8.1 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: py4j==0.10.7 in /home/ubuntu/.local/lib/python3.6/site-packages (0.10.7)\n",
      "\u001b[31mdtreeviz 0.8.1 has requirement graphviz>=0.9, but you'll have graphviz 0.8.1 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ! pip install py4j==0.10.7 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dtreeviz\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/6d/b3/960d6b83bd87b0e5d5f109a00dd25a3b3d6ecd8f6cf5a53fc0e080f23af5/dtreeviz-0.8.1.tar.gz\n",
      "Collecting graphviz>=0.9 (from dtreeviz)\n",
      "  Downloading https://files.pythonhosted.org/packages/f5/74/dbed754c0abd63768d3a7a7b472da35b08ac442cf87d73d5850a6f32391e/graphviz-0.13.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from dtreeviz)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from dtreeviz)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from dtreeviz)\n",
      "Requirement already satisfied: matplotlib in /Users/amardeepsingh/Library/Python/3.6/lib/python/site-packages (from dtreeviz)\n",
      "Collecting colour (from dtreeviz)\n",
      "  Downloading https://files.pythonhosted.org/packages/74/46/e81907704ab203206769dee1385dc77e1407576ff8f50a0681d0a6b541be/colour-0.1.5-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pytz>=2017.2 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from pandas->dtreeviz)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from pandas->dtreeviz)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /Users/amardeepsingh/Library/Python/3.6/lib/python/site-packages (from scikit-learn->dtreeviz)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/amardeepsingh/Library/Python/3.6/lib/python/site-packages (from matplotlib->dtreeviz)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/amardeepsingh/Library/Python/3.6/lib/python/site-packages (from matplotlib->dtreeviz)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/amardeepsingh/Library/Python/3.6/lib/python/site-packages (from matplotlib->dtreeviz)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas->dtreeviz)\n",
      "Requirement already satisfied: setuptools in /Users/amardeepsingh/Library/Python/3.6/lib/python/site-packages (from kiwisolver>=1.0.1->matplotlib->dtreeviz)\n",
      "Building wheels for collected packages: dtreeviz\n",
      "  Running setup.py bdist_wheel for dtreeviz ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/amardeepsingh/Library/Caches/pip/wheels/d8/74/06/0d9d450156c7cb2f1fcfb51a55b1542d26f459f557d742c406\n",
      "Successfully built dtreeviz\n",
      "Installing collected packages: graphviz, colour, dtreeviz\n",
      "Successfully installed colour-0.1.5 dtreeviz-0.8.1 graphviz-0.13.2\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ! pip3 install dtreeviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If for any reason this way of installing doesn't work for you straight out of the box, please refer to the more detailed documentation here: https://github.com/parrt/dtreeviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're ready to visualize your Decision Tree model! Please feel free to use the blog post for guidance and inspiration!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown option: -e\r\n",
      "usage: /usr/local/Cellar/python@2/2.7.16/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python [option] ... [-c cmd | -m mod | file | -] [arg] ...\r\n",
      "Try `python -h' for more information.\r\n"
     ]
    }
   ],
   "source": [
    "# !python -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling dependencies for graphviz: \u001b[32mpython\u001b[39m, \u001b[32mglib\u001b[39m, \u001b[32mjasper\u001b[39m, \u001b[32mnetpbm\u001b[39m, \u001b[32mgts\u001b[39m and \u001b[32mlibtool\u001b[39m\u001b[0m\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling graphviz dependency: \u001b[32mpython\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://homebrew.bintray.com/bottles/python-3.7.6_1.mojave.bottl\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://akamai.bintray.com/64/643d627c2b4fc03a3286c397d2992\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring python-3.7.6_1.mojave.bottle.tar.gz\u001b[0m\n",
      "\u001b[31mError:\u001b[0m The `brew link` step did not complete successfully\n",
      "The formula built, but is not symlinked into /usr/local\n",
      "Could not symlink bin/idle3\n",
      "Target /usr/local/bin/idle3\n",
      "already exists. You may want to remove it:\n",
      "  rm '/usr/local/bin/idle3'\n",
      "\n",
      "To force the link and overwrite all conflicting files:\n",
      "  brew link --overwrite python\n",
      "\n",
      "To list all files that would be deleted:\n",
      "  brew link --overwrite --dry-run python\n",
      "\n",
      "Possible conflicting files are:\n",
      "/usr/local/bin/idle3 -> /Library/Frameworks/Python.framework/Versions/3.6/bin/idle3\n",
      "/usr/local/bin/pydoc3 -> /Library/Frameworks/Python.framework/Versions/3.6/bin/pydoc3\n",
      "/usr/local/bin/python3 -> /Library/Frameworks/Python.framework/Versions/3.6/bin/python3\n",
      "/usr/local/bin/python3-config -> /Library/Frameworks/Python.framework/Versions/3.6/bin/python3-config\n",
      "/usr/local/bin/pyvenv -> /Library/Frameworks/Python.framework/Versions/3.6/bin/pyvenv\n",
      "/usr/local/Frameworks/Python.framework/Headers -> /usr/local/Cellar/python@2/2.7.16/Frameworks/Python.framework/Headers\n",
      "/usr/local/Frameworks/Python.framework/Python -> /usr/local/Cellar/python@2/2.7.16/Frameworks/Python.framework/Python\n",
      "/usr/local/Frameworks/Python.framework/Resources -> /usr/local/Cellar/python@2/2.7.16/Frameworks/Python.framework/Resources\n",
      "/usr/local/Frameworks/Python.framework/Versions/Current -> /usr/local/Cellar/python@2/2.7.16/Frameworks/Python.framework/Versions/Current\n",
      "\u001b[34m==>\u001b[0m \u001b[1m/usr/local/Cellar/python/3.7.6_1/bin/python3 -s setup.py --no-user-cfg insta\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1m/usr/local/Cellar/python/3.7.6_1/bin/python3 -s setup.py --no-user-cfg insta\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1m/usr/local/Cellar/python/3.7.6_1/bin/python3 -s setup.py --no-user-cfg insta\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mCaveats\u001b[0m\n",
      "Python has been installed as\n",
      "  /usr/local/bin/python3\n",
      "\n",
      "Unversioned symlinks `python`, `python-config`, `pip` etc. pointing to\n",
      "`python3`, `python3-config`, `pip3` etc., respectively, have been installed into\n",
      "  /usr/local/opt/python/libexec/bin\n",
      "\n",
      "If you need Homebrew's Python 2.7 run\n",
      "  brew install python@2\n",
      "\n",
      "You can install Python packages with\n",
      "  pip3 install <package>\n",
      "They will install into the site-package directory\n",
      "  /usr/local/lib/python3.7/site-packages\n",
      "\n",
      "See: https://docs.brew.sh/Homebrew-and-Python\n",
      "\u001b[34m==>\u001b[0m \u001b[1mSummary\u001b[0m\n",
      "🍺  /usr/local/Cellar/python/3.7.6_1: 3,977 files, 60.8MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling graphviz dependency: \u001b[32mglib\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://homebrew.bintray.com/bottles/glib-2.62.4.mojave.bottle.t\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://akamai.bintray.com/41/41e291828544ef7693b6a0284a8c7\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring glib-2.62.4.mojave.bottle.tar.gz\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mCaveats\u001b[0m\n",
      "Bash completion has been installed to:\n",
      "  /usr/local/etc/bash_completion.d\n",
      "\u001b[34m==>\u001b[0m \u001b[1mSummary\u001b[0m\n",
      "🍺  /usr/local/Cellar/glib/2.62.4: 435 files, 15.4MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling graphviz dependency: \u001b[32mjasper\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://homebrew.bintray.com/bottles/jasper-2.0.16_1.mojave.bott\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://akamai.bintray.com/ed/ed0856ff9b2429852401e658f4045\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring jasper-2.0.16_1.mojave.bottle.tar.gz\u001b[0m\n",
      "🍺  /usr/local/Cellar/jasper/2.0.16_1: 40 files, 1.4MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling graphviz dependency: \u001b[32mnetpbm\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://homebrew.bintray.com/bottles/netpbm-10.86.07.mojave.bott\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://akamai.bintray.com/f5/f537e20d981cc3aba9f53cadee4cb\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring netpbm-10.86.07.mojave.bottle.tar.gz\u001b[0m\n",
      "🍺  /usr/local/Cellar/netpbm/10.86.07: 410 files, 6.5MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling graphviz dependency: \u001b[32mgts\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://homebrew.bintray.com/bottles/gts-0.7.6_2.mojave.bottle.t\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://akamai.bintray.com/e0/e0ba5b2700ba2a0c88a6345117a69\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring gts-0.7.6_2.mojave.bottle.tar.gz\u001b[0m\n",
      "🍺  /usr/local/Cellar/gts/0.7.6_2: 27 files, 1.1MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling graphviz dependency: \u001b[32mlibtool\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://homebrew.bintray.com/bottles/libtool-2.4.6_1.mojave.bott\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://akamai.bintray.com/c9/c92ab35c3706c255a36b733aa7a47\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring libtool-2.4.6_1.mojave.bottle.tar.gz\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mCaveats\u001b[0m\n",
      "In order to prevent conflicts with Apple's own libtool we have prepended a \"g\"\n",
      "so, you have instead: glibtool and glibtoolize.\n",
      "\u001b[34m==>\u001b[0m \u001b[1mSummary\u001b[0m\n",
      "🍺  /usr/local/Cellar/libtool/2.4.6_1: 71 files, 3.7MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling \u001b[32mgraphviz\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://homebrew.bintray.com/bottles/graphviz-2.42.2.mojave.bott\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://akamai.bintray.com/ab/abf938b188d15e2bf1b7447635f1e\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring graphviz-2.42.2.mojave.bottle.tar.gz\u001b[0m\n",
      "🍺  /usr/local/Cellar/graphviz/2.42.2: 508 files, 11MB\n",
      "\u001b[34m==>\u001b[0m \u001b[1m`brew cleanup` has not been run in 30 days, running now...\u001b[0m\n",
      "Removing: /Users/amardeepsingh/Library/Caches/Homebrew/bazel--0.29.1.sh... (37.7MB)\n",
      "Removing: /usr/local/Cellar/python/3.7.2... (7,953 files, 111.6MB)\n",
      "Removing: /usr/local/Cellar/python/3.7.2_2... (8,464 files, 118.4MB)\n",
      "Removing: /usr/local/Cellar/readline/7.0.5... (46 files, 1.5MB)\n",
      "Removing: /usr/local/Cellar/readline/8.0.0... (48 files, 1.5MB)\n",
      "Removing: /usr/local/Cellar/sqlite/3.25.2... (11 files, 3.7MB)\n",
      "Removing: /usr/local/Cellar/sqlite/3.26.0... (11 files, 3.7MB)\n",
      "Removing: /usr/local/Cellar/sqlite/3.27.1... (11 files, 3.7MB)\n",
      "Removing: /Users/amardeepsingh/Library/Logs/Homebrew/bazel... (2 files, 3.1KB)\n",
      "Pruned 0 symbolic links and 8 directories from /usr/local\n",
      "\u001b[32m==>\u001b[0m \u001b[1mCaveats\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mpython\u001b[0m\n",
      "Python has been installed as\n",
      "  /usr/local/bin/python3\n",
      "\n",
      "Unversioned symlinks `python`, `python-config`, `pip` etc. pointing to\n",
      "`python3`, `python3-config`, `pip3` etc., respectively, have been installed into\n",
      "  /usr/local/opt/python/libexec/bin\n",
      "\n",
      "If you need Homebrew's Python 2.7 run\n",
      "  brew install python@2\n",
      "\n",
      "You can install Python packages with\n",
      "  pip3 install <package>\n",
      "They will install into the site-package directory\n",
      "  /usr/local/lib/python3.7/site-packages\n",
      "\n",
      "See: https://docs.brew.sh/Homebrew-and-Python\n",
      "\u001b[34m==>\u001b[0m \u001b[1mglib\u001b[0m\n",
      "Bash completion has been installed to:\n",
      "  /usr/local/etc/bash_completion.d\n",
      "\u001b[34m==>\u001b[0m \u001b[1mlibtool\u001b[0m\n",
      "In order to prevent conflicts with Apple's own libtool we have prepended a \"g\"\n",
      "so, you have instead: glibtool and glibtoolize.\n"
     ]
    }
   ],
   "source": [
    "# !brew install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here! :)\n",
    "from dtreeviz.trees import *\n",
    "viz = dtreeviz(dtc_model, \n",
    "               X_train, \n",
    "               y_train,\n",
    "               target_name='GC',\n",
    "              feature_names=X_train.columns, \n",
    "               class_names=[\"1\", \"2\"]  # need class_names for classifier\n",
    "              )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.save('dt_test.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini_Project_Tree-Based_Algorithms.ipynb\r\n",
      "test\r\n",
      "test.svg\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in the lecture videos, Decision Tree algorithms also have certain undesireable properties. Mainly the have low bias, which is good, but tend to have high variance - which is *not* so good (more about this problem here: https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noticing these problems, the late Professor Leo Breiman, in 2001, developed the Random Forests algorithm, which mitigates these problems, while at the same time providing even higher predictive accuracy than the majority of Decision Tree algorithm implementations. While the curriculum contains two excellent lectures on Random Forests, if you're interested, you can dive into the original paper here: https://link.springer.com/content/pdf/10.1023%2FA%3A1010933404324.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next part of this assignment, your are going to use the same \"German Credit\" dataset to train, tune, and measure the performance of a Random Forests model. You will also see certain functionalities that this model, even though it's a bit of a \"black box\", provides for some degree of interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's build a Random Forests model, using the same best practices that you've used for your Decision Trees model. You can reuse the things you've already imported there, so no need to do any re-imports, new train/test splits, or loading up the data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here! :)\n",
    "rfc_model = RandomForestClassifier()\n",
    "rfc_model.fit(X_train,y_train)\n",
    "y_pred = rfc_model.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'tree_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-9637e36f4185>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                \u001b[0mtarget_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'GC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# need class_names for classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m               )  \n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/dtreeviz/trees.py\u001b[0m in \u001b[0;36mdtreeviz\u001b[0;34m(tree_model, X_train, y_train, feature_names, target_name, class_names, precision, orientation, show_root_edge_labels, show_node_labels, show_just_path, fancy, histtype, highlight_path, X, max_X_features_LR, max_X_features_TD, label_fontsize, ticks_fontsize, fontname, colors, scale)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m     shadow_tree = ShadowDecTree(tree_model, X_train, y_train,\n\u001b[0;32m--> 766\u001b[0;31m                                 feature_names=feature_names, class_names=class_names)\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/dtreeviz/shadow.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tree_model, X_train, y_train, feature_names, class_names)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tree_'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# make sure model is fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mtree_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'tree_'"
     ]
    }
   ],
   "source": [
    "rfc_viz = dtreeviz(rfc_model, \n",
    "               X_train, \n",
    "               y_train,\n",
    "               target_name='GC',\n",
    "              feature_names=X_train.columns, \n",
    "               class_names=[\"1\", \"2\"]  # need class_names for classifier\n",
    "              )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_viz.save('rfc_viz.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, there are certain ways to \"peek\" into a model created by the Random Forests algorithm. The first, and most popular one, is the Feature Importance calculation functionality. This allows the ML practitioner to see an ordering of the importance of the features that have contributed the most to the predictive accuracy of the model. \n",
    "\n",
    "You can see how to use this in the scikit-learn documentation (http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.feature_importances_). Now, if you tried this, you would just get an ordered table of not directly interpretable numeric values. Thus, it's much more useful to show the feature importance in a visual way. You can see an example of how that's done here: http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html#sphx-glr-auto-examples-ensemble-plot-forest-importances-py\n",
    "\n",
    "Now you try! Let's visualize the importance of features from your Random Forests model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A final method for gaining some insight into the inner working of your Random Forests models is a so-called Partial Dependence Plot. The Partial Dependence Plot (PDP or PD plot) shows the marginal effect of a feature on the predicted outcome of a previously fit model. The prediction function is fixed at a few values of the chosen features and averaged over the other features. A partial dependence plot can show if the relationship between the target and a feature is linear, monotonic or more complex. \n",
    "\n",
    "In scikit-learn, PDPs are implemented and available for certain algorithms, but at this point (version 0.20.0) they are not yet implemented for Random Forests. Thankfully, there is an add-on package called **PDPbox** (https://pdpbox.readthedocs.io/en/latest/) which adds this functionality to Random Forests. The package is easy to install through pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! pip install pdpbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we encourage you to read the documentation for the package (and reading package documentation in general is a good habit to develop), the authors of the package have also written an excellent blog post on how to use it, showing examples on different algorithms from scikit-learn (the Random Forests example is towards the end of the blog post): https://briangriner.github.io/Partial_Dependence_Plots_presentation-BrianGriner-PrincetonPublicLibrary-4.14.18-updated-4.22.18.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, armed with this new knowledge, feel free to pick a few features, and make a couple of Partial Dependence Plots of your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Advanced Boosting-Based Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained in the video lectures, the next generation of algorithms after Random Forests (that use Bagging, a.k.a. Bootstrap Aggregation) were developed using Boosting, and the first one of these were Gradient Boosted Machines, which are implemented in scikit-learn (http://scikit-learn.org/stable/modules/ensemble.html#gradient-tree-boosting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, in recent years, a number of variations on GBMs have been developed by different research amd industry groups, all of them bringing improvements, both in speed, accuracy and functionality to the original Gradient Boosting algorithms.\n",
    "\n",
    "In no order of preference, these are:\n",
    "1. **XGBoost**: https://xgboost.readthedocs.io/en/latest/\n",
    "2. **CatBoost**: https://tech.yandex.com/catboost/\n",
    "3. **LightGBM**: https://lightgbm.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're using the Anaconda distribution, these are all very easy to install:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! conda install -c anaconda py-xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! conda install -c conda-forge catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! conda install -c conda-forge lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task in this optional section of the mini project is to read the documentation of these three libraries, and apply all of them to the \"German Credit\" dataset, just like you did in the case of Decision Trees and Random Forests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final deliverable of this section should be a table (can be a pandas DataFrame) which shows the accuracy of all the five algorthms taught in this mini project in one place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Happy modeling! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
